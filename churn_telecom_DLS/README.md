# Отток клиентов (DLS)

## Описание проекта

В данном проекте мы будем решать задачу предсказания оттока клиентов  
Это задача бинарной классификации (ушел/не ушел)

Проект - задача из продвинутого курса DeepLearningSchool, данный проект был проверен на платформе Stepik другими студентами курса, поэтому реализовывал его с максимально подробными объяснениями своих действий и вариантами решения, для того чтобы другие студенты могли посмотреть как выглядят решения с хорошей структурой, понятными для заказчиков выводами и комментариями, а также подчепрнули для себя методы анализа данных и моделей, но все же из за сроков пришлось урезать часть с подробным EDA до MVP, чем очень огорчен, так как это одно из моих любимых занятий. Каждый может!

### Данные
train.csv - файл с тренировочной выборкой  
test.csv - файл с тестовой выборкой  
submission.csv - файл с примером оформления результата работы

### Метрика
В проекте мы используем для тестирования стандартную для задачи классификации метрику ROC-AUC.  
Она работает даже если классы в данных сильно несбалансированны (примеров одного класса в десятки раз больше примеров другого).

## План проекта

1. Загрузим данные и проведем первичный осмотр данных
2. Проведем исследовательский анализ и предобработаем данные
3. Исследуем несколько моделей и выберем финальную модель
5. Протестируем лучшую модель на отложенной выборке и получим финальную метрику

## Что было сделано в проекте

## Финальный вывод
Мы проделали огромную работу, а именно:

+ Загрузили и изучили данные, нашли проблемные места:

    + Размер тренировочной выборки 5282 объекта на 20 признаков
    + В тренировочной выборке 3 признака непрерывных и 17 категориальных (8 из которых бинарные) один из них наш целевой признак,
    + Признаки имели формат PascalCase, перевели в привычный парселтанг (snake_case),
    + Признак total_spent имел некорректный тип данных object - перевели в float, также имелись пустые значения в количестве 9 штук (пустая строка), заменили на NaN провели анализ гипотезы и приняли решение заполнить пропущенные значения значениями из признака monthly_spending
    + Тип признака is_senior_citizen числовой, уже преобразованный, оставим его для кодировщиков
    + Дубликаты в данной задаче не имеют значения, так как возможны полные копии наблюдений, но могут относится к разным пользователям, в данном случае присутствуют полные дубликаты наблюдений с временем пользования сервисами равным одному месяцу
    + Пропусков нет


+ Провели исследовательский анализ данных, а также определили среднего пользователя компании:

    + Категориальные признаки:
        + Целевой признак несбалансирован, соотношение 76 к 24%, необходимо это учесть при исследовании моделей
        + Способ оплаты доминирует electronic_check, остальные способы примерно равны между собой
        + Большая часть пользователей предпочитает не получать бумажные чеки
        + У большинства пользователей подключена помесячная подписка на телефон, в два раза меньше пользователей пользуются двухгодичной подпиской, немного меньше ежегодной
        + Примерно одинаковое количество людей кто пользуется подпиской на фильмы и тех у кого нет подписки, в половину меньше у кого нет интернет сервиса
        + У большего числа пользователей нет онлайн тв, чуть меньше пользователей имеют телевидение, в два раза меньше пользователей у которых нет интернет сервиса
        + Большее число пользователей не имеют сервиса технической поддержки
        + Также дела обстоят с сервисом защиты устройств, онлайн резеврной копией, онлайн службой безопасности
        + Большинство пользователей использую оптоволоконное подключение, чуть меньше пользователей используют цифровое подключение
        + Возможностю подключения телефонного номера к нескольким линиям одновременно не пользуется большинство пользователей, чуть меньше подключили такую услугу, достаточно мало человек не используют телефонные сервисы
        + Распределение в выборке мужчин и женщин примерно одинаково, такая же ситуация с наличием партнера, большинство не имеет детей и не пенсионного возраста
    
    
    + Численные признаки:
        + client_period:

            Гистограмма для client_period показывает, что большинство клиентов пользовались услугами компании относительно недавно, с низким значением client_period.  
            Это видно из высокого столбца близкого к 0 на гистограмме.   
            Со временем количество клиентов убывает, что видно из уменьшения высоты столбцов при увеличении client_period.
            Однако есть также большая доля клиентов, которые пользуются услугами длительное время и составляют второй пик в конце.
            Распределение признака напоминает экспоненциальное распределение с двумя пиками.

        + monthly_spending:

            Гистограмма для monthly_spending показывает, что есть пик при низких ежемесячных трат и более равномерное низкое распределение далее, меньше всего пользователей с ежемесечной платой в диапазоне от 30 до 45.   
            Это указывает на наличие основной группы клиентов: с низкими ежемесячными расходами.   
            Распределение признака является одномодальным, с одним характерным значением.  

        + total_spent:

            Распределение признака total_spent является также одномодальным, с одним характерным значением, и показывает, что большинство клиентов имеют низкие общие траты.
            Присутствует жирный хвост до значений больше 8_000  
            Значения плавно уходят в жирный хвост, с увеличением общих трат и уменьшается количество пользователей.  
            Распределение признака является одномодальным.
            
+ Перед исследованием моделей изучили важность признаков с помощью фи-ка:
        
    + Матрица корреляции:

        + Сильная корреляция между некоторыми признаками:   
            Все признаки интернет сервисов очень сильно положительно коррелируют друг с другом, что приведет к мультиколлинеарности  
            Это усложняет интерпретацию важности каждого из этих признаков и может привести к нестабильным оценкам модели. Например, has_online_security_service, has_online_backup, has_device_protection, и has_tech_support_access сильно коррелируют друг с другом. Рассмотрим удаление некоторых из них.

        + Слабая корреляция с целевой переменной:  
            Некоторые признаки имеют низкую корреляцию с целевой переменной churn. Например, has_multiple_phone_numbers, sex, has_phone_service имеют практически нулевую корреляцию с churn.   
            Эти признаки не предоставляют значимой информации для прогнозирования ухода клиентов и могут быть исключены.

        + Смещение в данных:
            Имеется неравномерное распределение значений в некоторых признаках, что может вызвать проблемы при обучении модели. Например, если у большинства клиентов значение признака близко к нулю, это может привести к смещению модели.  
            Будем нормировать численные признаки

        + Сильные стороны:

            Корреляция с целевой переменной: Некоторые признаки, такие как client_period, payment_method, monthly_spending, имеют среднюю корреляцию с целевой переменной churn. Эти признаки могут быть полезны для прогнозирования ухода клиентов.  


На первой итерации мы старались максимально сохранить всю информацию о данных
    
+ Мы провели большое исследование и изучили 3 модели:
    + LogisticRegression:  
        Для этой линейной модели мы использовали преобразование числовых (StandardScaler) и категориальных признаков (OHE)  
        После мы преобразовали признаки методом главных компонент, для устранения очень высокой корреляции между признаками
        Провели подбор гиперпараметров на кросс-валидации и замерили качество по метрике ROC_AUC
        Модель оказалась самой быстрой из всех исследованных, но качество меньше, чем у последующих
    + RandomForestClassifier:  
        Признаки для этой модели мы преобразовали таким же способом как и у предыдущей модели
        Модель значительно дольше обучалась на кросс-валидации, перебрали больше гиперпараметров и получили метрику выше, чем у бейзлайн-модели
    + CatBoostClassifier:
        Для данной модели мы не масштабировали признаки, она хорошо справляется с этим сама, от нас было необходимо только указать категориальные признаки, для их дальнейшей обработки в самой модели, что мы и сделали
        По времени эта модель была сравнима с случайным лесом и получила самый высокий скор среди тестируемых моделей, именно ее мы и выбрали для финального тестирования на отложенной выборке
        
        
## Итог

Мы можем сказать, что с достаточной точность можем предсказывать уход пользователей и с задачей справились

## UPD

На следующей итерации необходимо будет добавить функцию, для вывода графиков conf_matrix и roc_curve, иначе не комильфо



